#!/usr/bin/env python3
"""
Data Upload Module for Tech Challenge 03
Download and process Spotify recommendation dataset from Kaggle
"""

import sys
import logging
import shutil
from pathlib import Path
from typing import Optional, Dict, Any
import kagglehub
from kagglehub import KaggleDatasetAdapter

# Configura√ß√£o de logging - apenas terminal
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class SpotifyDataDownloader:
    """Classe para gerenciar o download e carregamento do dataset do Spotify"""
    
    def __init__(self, dataset_name: str = 'minahilfatima12328/daily-coffee-transactions'):
        """
        Inicializa o downloader
        
        Args:
            dataset_name: Nome do dataset no Kaggle
        """
        self.dataset_name = dataset_name
        self.data_dir = Path('data')
        self.data_dir.mkdir(exist_ok=True)
        
    def download_dataset(self, force_download: bool = False, copy_to_local: bool = True) -> str:
        """
        Baixa o dataset do Kaggle e opcionalmente copia para diret√≥rio local
        
        Args:
            force_download: For√ßa o download mesmo se j√° existir
            copy_to_local: Se True, copia arquivos para diret√≥rio local do projeto
            
        Returns:
            str: Caminho onde os dados foram salvos (local se copy_to_local=True)
        """
        try:
            logger.info(f"Iniciando download do dataset: {self.dataset_name}")
            
            # Usar o m√©todo dataset_download para baixar os arquivos
            kaggle_cache_path = kagglehub.dataset_download(
                self.dataset_name, 
                force_download=force_download
            )
            
            logger.info(f"Dataset baixado do Kaggle em: {kaggle_cache_path}")
            
            if copy_to_local:
                local_path = self.copy_to_local_directory(kaggle_cache_path)
                logger.info(f"Arquivos copiados para diret√≥rio local: {local_path}")
                return local_path
            else:
                return kaggle_cache_path
            
        except Exception as e:
            logger.error(f"Erro ao baixar dataset: {str(e)}")
            raise
            
    def copy_to_local_directory(self, source_path: str) -> str:
        """
        Copia arquivos do cache do Kaggle para o diret√≥rio local do projeto
        
        Args:
            source_path: Caminho do cache do Kaggle
            
        Returns:
            str: Caminho do diret√≥rio local onde os arquivos foram copiados
        """
        try:
            source_dir = Path(source_path)
            local_data_dir = self.data_dir / 'coffee_dataset'
            
            # Criar diret√≥rio local se n√£o existir
            local_data_dir.mkdir(parents=True, exist_ok=True)
            
            logger.info(f"Copiando arquivos de {source_dir} para {local_data_dir}")
            
            copied_files = []
            for file_path in source_dir.glob('*'):
                if file_path.is_file():
                    destination = local_data_dir / file_path.name
                    shutil.copy2(file_path, destination)
                    copied_files.append(file_path.name)
                    logger.info(f"  ‚úÖ Copiado: {file_path.name} ({file_path.stat().st_size} bytes)")
            
            logger.info(f"Total de {len(copied_files)} arquivo(s) copiado(s) para o diret√≥rio local")
            return str(local_data_dir)
            
        except Exception as e:
            logger.error(f"Erro ao copiar arquivos para diret√≥rio local: {str(e)}")
            raise
            
    def load_dataset_as_dataframe(self, file_path: str = "") -> Any:
        """
        Carrega o dataset como DataFrame usando kagglehub.load_dataset
        
        Args:
            file_path: Caminho espec√≠fico do arquivo (opcional)
            
        Returns:
            DataFrame: Dataset carregado como pandas DataFrame
        """
        try:
            logger.info(f"Carregando dataset como DataFrame: {self.dataset_name}")
            
            # Verificar se pandas est√° dispon√≠vel
            try:
                import pandas as pd
                logger.info("Pandas dispon√≠vel para carregamento")
            except ImportError:
                logger.error("Pandas n√£o est√° instalado")
                raise ImportError("Pandas √© necess√°rio para carregar como DataFrame")
            
            # Carregar usando KaggleDatasetAdapter.PANDAS
            df = kagglehub.load_dataset(
                KaggleDatasetAdapter.PANDAS,
                self.dataset_name,
                file_path,
                # Par√¢metros adicionais do pandas podem ser passados aqui
                pandas_kwargs={"index_col": 0} if file_path else {}
            )
            
            logger.info(f"Dataset carregado com sucesso. Shape: {df.shape}")
            return df
            
        except ImportError as ie:
            logger.error(f"Erro de importa√ß√£o: {str(ie)}")
            logger.info("Instale com: pip install kagglehub[pandas-datasets]")
            raise
        except Exception as e:
            logger.error(f"Erro ao carregar dataset como DataFrame: {str(e)}")
            raise
            
    def verify_download(self, path: str) -> bool:
        """
        Verifica se o download foi bem-sucedido
        
        Args:
            path: Caminho dos dados baixados
            
        Returns:
            bool: True se o download foi bem-sucedido
        """
        try:
            download_path = Path(path)
            if not download_path.exists():
                logger.error(f"Caminho n√£o existe: {path}")
                return False
                
            # Verificar se h√° arquivos no diret√≥rio
            files = list(download_path.glob('*'))
            if not files:
                logger.error(f"Nenhum arquivo encontrado em: {path}")
                return False
                
            logger.info(f"Verifica√ß√£o bem-sucedida. Arquivos encontrados:")
            for file in files:
                if file.is_file():
                    logger.info(f"  - {file.name} ({file.stat().st_size} bytes)")
                
            return True
            
        except Exception as e:
            logger.error(f"Erro na verifica√ß√£o: {str(e)}")
            return False
            
    def list_downloaded_files(self, path: str) -> list:
        """
        Lista os arquivos baixados
        
        Args:
            path: Caminho dos dados baixados
            
        Returns:
            list: Lista de arquivos encontrados
        """
        try:
            download_path = Path(path)
            if not download_path.exists():
                return []
                
            files = [str(file) for file in download_path.glob('*') if file.is_file()]
            return sorted(files)
            
        except Exception as e:
            logger.error(f"Erro ao listar arquivos: {str(e)}")
            return []
            
    def get_local_csv_path(self) -> Optional[Path]:
        """
        Retorna o caminho do arquivo CSV local se existir
        
        Returns:
            Path: Caminho do arquivo CSV local ou None se n√£o existir
        """
        local_data_dir = self.data_dir / 'spotify_dataset'
        csv_file = local_data_dir / 'data.csv'
        
        if csv_file.exists():
            return csv_file
        return None
        
    def load_local_csv_as_dataframe(self) -> Any:
        """
        Carrega o arquivo CSV local como DataFrame
        
        Returns:
            DataFrame: Dataset carregado como pandas DataFrame
        """
        try:
            import pandas as pd
            
            csv_path = self.get_local_csv_path()
            if not csv_path:
                raise FileNotFoundError("Arquivo CSV local n√£o encontrado. Execute o download primeiro.")
            
            logger.info(f"Carregando CSV local: {csv_path}")
            df = pd.read_csv(csv_path, index_col=0)
            logger.info(f"CSV local carregado com sucesso. Shape: {df.shape}")
            
            return df
            
        except Exception as e:
            logger.error(f"Erro ao carregar CSV local: {str(e)}")
            raise


def setup_environment() -> bool:
    """Configura o ambiente necess√°rio"""
    try:
        # Verificar se as credenciais do Kaggle est√£o configuradas
        kaggle_config = Path.home() / '.kaggle' / 'kaggle.json'
        if not kaggle_config.exists():
            logger.warning("Arquivo de credenciais do Kaggle n√£o encontrado!")
            logger.info("Configure suas credenciais em: ~/.kaggle/kaggle.json")
            logger.info("Ou use as vari√°veis de ambiente KAGGLE_USERNAME e KAGGLE_KEY")
            
        # Verificar depend√™ncias
        try:
            import pandas as pd
            logger.info("‚úÖ Pandas dispon√≠vel")
        except ImportError:
            logger.warning("‚ùå Pandas n√£o est√° dispon√≠vel")
            logger.info("Instale com: pip install pandas")
            return False
            
        return True
        
    except Exception as e:
        logger.error(f"Erro na configura√ß√£o do ambiente: {str(e)}")
        return False


def main() -> int:
    """Fun√ß√£o principal para download dos dados do Spotify"""
    logger.info("=" * 60)
    logger.info("TECH CHALLENGE 03 - SPOTIFY DATA UPLOAD")
    logger.info("=" * 60)
    
    try:
        # Configurar ambiente
        if not setup_environment():
            logger.error("Falha na configura√ß√£o do ambiente")
            return 1
            
        # Criar inst√¢ncia do downloader
        downloader = SpotifyDataDownloader()
        
        # M√©todo 1: Download e c√≥pia para diret√≥rio local
        logger.info("üìÅ M√©todo 1: Download e c√≥pia para diret√≥rio local...")
        path_download = downloader.download_dataset(copy_to_local=True)
        
        if downloader.verify_download(path_download):
            files = downloader.list_downloaded_files(path_download)
            logger.info(f"‚úÖ Download e c√≥pia local conclu√≠dos. {len(files)} arquivo(s) salvos")
            
            # Mostrar alguns arquivos encontrados
            for i, file in enumerate(files[:5]):  # Mostrar at√© 5 arquivos
                logger.info(f"   üìÑ {Path(file).name}")
                
            # Verificar se CSV local est√° dispon√≠vel
            csv_path = downloader.get_local_csv_path()
            if csv_path:
                logger.info(f"   üéØ Arquivo CSV principal: {csv_path}")
        else:
            logger.error("‚ùå Falha na verifica√ß√£o do download")
            return 1
            
        # M√©todo 2: Carregamento do CSV local como DataFrame
        logger.info("üìä M√©todo 2: Carregamento do CSV local como DataFrame...")
        try:
            df = downloader.load_local_csv_as_dataframe()
            logger.info(f"‚úÖ CSV local carregado como DataFrame!")
            logger.info(f"   üìè Dimens√µes: {df.shape}")
            logger.info(f"   üìã Colunas: {list(df.columns)}")
            
            # Mostrar informa√ß√µes estat√≠sticas b√°sicas
            logger.info("üìà Informa√ß√µes estat√≠sticas:")
            logger.info(f"   üéµ Total de m√∫sicas: {len(df)}")
            if 'liked' in df.columns:
                liked_count = df['liked'].sum()
                logger.info(f"   ‚ù§Ô∏è  M√∫sicas curtidas: {liked_count}")
                logger.info(f"   üíî M√∫sicas n√£o curtidas: {len(df) - liked_count}")
            
            # Mostrar primeiras linhas
            logger.info("üìñ Primeiras 5 linhas do dataset:")
            print("\n" + "="*70)
            print(df.head())
            print("="*70 + "\n")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Erro ao carregar CSV local: {str(e)}")
            
            # Fallback: tentar m√©todo original do kagglehub
            try:
                logger.info("ÔøΩ Tentando m√©todo alternativo com kagglehub...")
                df = downloader.load_dataset_as_dataframe("data.csv")
                logger.info(f"‚úÖ Dataset carregado via kagglehub!")
                logger.info(f"   üìè Dimens√µes: {df.shape}")
                
            except Exception as e2:
                logger.warning(f"‚ö†Ô∏è  M√©todo alternativo tamb√©m falhou: {str(e2)}")
            
        logger.info("=" * 60)
        logger.info("‚úÖ PROCESSO CONCLU√çDO COM SUCESSO!")
        logger.info("=" * 60)
        
        return 0
        
    except KeyboardInterrupt:
        logger.info("üõë Processo interrompido pelo usu√°rio")
        return 1
        
    except Exception as e:
        logger.error(f"‚ùå Erro inesperado: {str(e)}")
        logger.exception("Detalhes do erro:")
        return 1


if __name__ == "__main__":
    """Ponto de entrada do script"""
    exit_code = main()
    sys.exit(exit_code)